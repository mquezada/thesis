\subsection{Background}\label{sec:related}
% There is extensive work on automatic summarization on microblogs\mq{ref}. In
% this work, we approach the problem from a practical point of view, where our
% goal is to benefit from the characteristics of social media posts, in
% particular, from event-related messages. We exploit the redundancy of
% information available in social media via the aggregation of information
% around shared URLs, and propose a simple and compact model using word
% embeddings on tweets. Therefore, we can classify the related work in three
% areas: modeling social media content, automatic summarization of news, and
% usage of word embeddings in social media.

Two lines of research are relevant to our work: the utility of anchor texts in
microblogs and topic detection methods using different aggregation strategies. 

%\bp{No hay literatura de representaciones compactas de eventos para sumarizacion?}

%
About the usefulness of anchor texts on Twitter, Raux et
al.~\cite{raux2011describing} used anchor texts from tweets pointing to a
predefined set of URLs to characterize general topics, by clustering a bipartite
graph of words and URLs. 
%
We instead focus on news events, and tweets related to these news, which have
their own particularities, in contrast to long lasting general topics. 
%
Mishne and Lin~\cite{mishne2012twanchor} studied the contribution of anchor
texts compared to the text of the websites behind the URLs, concluding that
anchor text add new terms not seen in the website content, by looking also at
the conversations around the sharing tweets. 
%
Alonso et al.~\cite{Alonso:2015:WCW:2740908.2745397} had similar findings
examining Facebook posts. 
%
In another work by Alonso et al.~\cite{Alonso:2017:WHH:3091478.3091484}, the
authors designed a social search engine using the propagation of shared URLs as
cues to measure virality, and anchor texts to augment metadata of the search
results with social content. 
%
In a previous work~\cite{quezada2013understanding}, we showed a proof of concept
of automatic summarization of documents using anchor texts.
%


Topic modeling of tweets is an active line of research, and there are some
studies which investigate the effectiveness of aggregation of tweets to improve
topic
detection~\cite{Hong:2010:EST:1964858.1964870,Mehrotra:2013:ILT:2484028.2484166,alvarez2016topic}.
Hong and Davison~\cite{Hong:2010:EST:1964858.1964870} analyzed the effects of
different aggregation strategies of tweets when finding topics with Latent
Dirichlet Allocation (LDA). 
%
They found that some schemes yield better results at some tasks, such as
classification problems related to tweets. 
%
In a similar fashion, Mehrotra et al.~\cite{Mehrotra:2013:ILT:2484028.2484166}
observed that aggregating hashtags (also described as {\em pooling} of tweets by
hashtags) is a more effective strategy to identify topics from tweets, but at
the cost of longer running times due to the duplication of tweets. 
%
Finally, Alvarez-Melis and Saveski~\cite{alvarez2016topic} found that adding the
threads of conversation into the pooling is more effective than pooling by
hashtag in their observations. 
%
We instead aggregate by shared URLs and conversations, with the goal of
generating a compact representation without major loss of information.



% \subsection{Using common information in tweets}

% Similar to our work, in the sense of exploiting common information across
% messages, the work of Kamath et al.~\cite{Kamath:2013:SDO:2488388.2488447}
% focuses in the spatio-temporal dynamics of {\em memes}, as seen as units of
% information spreaded in social media. For this, they model each tweet as a
% tuple of the hashtags involved, time, and location to observe and characterize
% topics in Twitter. Similarly, the work of Pe\~na-Araya et
% al.~\cite{pena2017gaining} aim to characterize geopolitical entities (such as
% countries) based on the tweets that mention them, by proposing a model to
% represent locations in a spatio-temporal ambit, and develop a visual analytics
% tool to explore events based on the location scope of their impact. Our work
% is similar to both in the sense of leveraging common entities across messages,
% in this case, the URLs, in order to generate a compact representation to
% facilitate the discovering of sub-events. In our case, we do so by using URLs
% and the text content as a surrogate for the URLs, also called anchor texts.

% Concerning the specific use of anchor text in social media, Mishne and
% Lin~\cite{mishne2012twanchor} show that the anchor texts in general tweets
% provide additional new information compared to the content of webpages alone
% in a study of 7 million URLs obtained from the Twitter Firehose. The work of
% Raux et al.~\cite{raux2011describing} is one of the first to use anchor texts
% to find clusters of topics in Twitter, in order to describe Web content using
% tweets. The authors create a weighted bipartite graph of tweet words and URLs,
% being the weight the tf-idf score of the words in the tweets that contain the
% URL, and then find clusters of URLs. Although they characterize clusters of
% URLs as topics, their work focuses on general tweets and not newsworthy
% messages in particular. In the work of Alonso et
% al.~\cite{Alonso:2017:WHH:3091478.3091484}, the authors develop a search
% engine for content related to URLs shared on Twitter, displaying the most
% popular and viral URLs, also showing the effectiveness of this approach. In
% our previous work~\cite{quezada2013understanding}, we show a prototype of a
% automatic summarization methodology using tweets aggregated by URL, and then
% modeling the aggregated sets as tf-idf vectors to cluster them, find sub-events, 
% and then selecting the most representative messages as a multi-modal
% summary.

% % \subsection{General text representation methods}

% % % verificar
% % %In a general domain, LDA is very good to find/extract topics, but not in the 
% % %domain of this work. So my magnificent research is pretty very much fabulous.

% % Topic models are a useful way to deal with textual information and to derive a
% % low-dimensional representation of documents. One of the most popular methods
% % is Latent Dirichlet Allocation, or LDA~\cite{blei2003latent}. LDA models a
% % document as a mixture of different topics, which are probability distributions
% % on the vocabulary. TwitterLDA~\cite{zhao2011comparing} is a modification to the 
% % original approach, by changing the assumption that a single document can discuss different topics, which may be unlikely in short messages, such as tweets. Our representation is 
% % compatible with LDA or TwitterLDA, as it provides a way to aggregate topical information which can
% % be used as input for topic models.

% % We also use dense word embeddings such as the continuous representations obtained by using shallow
% % neural networks such as {\tt word2vec}~\cite{DBLP:journals/corr/abs-1301-3781} 
% % or {\tt fastText}~\cite{bojanowski2016enriching}. Dense vector representation of words
% % provide a efficient way to assess the similarity of terms or documents. In contrast,
% % traditional methods, such as tf-idf~\cite{Salton:1983:EBI:182.358466}, involve generating embedding of words of thousands of dimensions, as high as the vocabulary size. Some methods, such as
% % Latent Semantic Analysis~\cite{dumais2004latent}, aims to reduce the dimensionality of the representation by doing matrix factorization. In our case, our model aims to generate a representation of low dimensionality by using neural word embeddings over the aggregation of 
% % related messages, and by doing so, reducing the amount of documents.


% \subsection{Applications of tweet representations}

% Automatic text summarization has been employed in different domains, such as
% news~\mq{cite}, sports~\cite{meladianos2018optimization,chakrabarti2011event},
% music~\cite{raposo2016using}, or movies~\cite{aparicio2016summarization}.

% There are several approaches for automatic summarization of events from social
% media, being many of them inspired in automatic text summarization. In order
% to manage scale, most of the related approaches do not deal with all the data
% at once, but work with similar sub-problems, such as sub-events detected via
% time windows, clustering, or online approaches. 

% The work of Chakrabarti and Punera~\cite{chakrabarti2011event} identifies
% particular time windows in structure-rich events, such as football matches.
% Using Hidden Markov Models, the authors find time windows associated with
% specific sub-events (e.g., a "touchdown") and then summarize each sub-event
% using a centroid-based approach on the tf-idf representation of the tweets.
% Similarly, Alsaedi et al.~\cite{alsaedi2016temporal} fix a time window of one
% hour to define all the tweets in that time window as a cluster, and then use
% two consecutive clusters to take into account the changes between time
% windows. They also propose two additional approaches, namely using a retweet
% voting approach and a temporal centroid method. In all cases, the approaches
% do not use all the dataset at once, but select a limited amount of messages as
% a sub-event. 

% We do not follow this approach, mainly because different sub-events  
% may be mentioned in different stages of the event, and the time-window
% approach can result in low purity clusters when being applied to general
% events.


% One of the first online approaches to event detection and summarization in
% Twitter is the work of Sankaranarayanan et
% al.~\cite{Sankaranarayanan:2009:TNT:1653771.1653781}. The authors describe a
% system that collects tweets and identifies events using an online clustering
% procedure over a tf-idf representation of tweets. \mq{problema con esto}




% \mq{completar (eval)} There is no definitive standard against which one can
% compare the results from an automated summarization system. In general, the
% methods for evaluating summaries can be classified in two kinds: intrinsic or
% extrinsic. The first one evaluate the quality of the summary itself, e.g.,
% compare the summary generated by the system with other summaries generated by
% human experts, whereas the extrinsic evaluate how the summary helps the
% accomplishment of another task, such as classification.


